# ðŸŒ½ Maize Disease Predictor

This project develops a web application for classifying common maize leaf diseases using deep learning, providing quick diagnoses and AI-powered treatment recommendations.

## Table of Contents

- [Project Overview](#project-overview)
- [Features](#features)
- [How to Run Locally](#how-to-run-locally)
- [Live Streamlit App](#live-streamlit-app)
- [Dataset](#dataset)
- [Model Details](#model-details)
- [Project Structure](#project-structure)
- [Group Members](#group-members)
- [Acknowledgements](#acknowledgements)

---

## Project Overview

Maize (corn) is a vital crop globally, but its yield is significantly impacted by various diseases. Early and accurate disease detection is crucial for effective management and preventing widespread crop loss. This project aims to assist farmers and agricultural experts by providing a fast, accessible tool for identifying common maize leaf diseases using image classification.

The application leverages transfer learning with a fine-tuned ResNet50 model to classify images into categories such as Blight, Common Rust, Gray Leaf Spot, or Healthy. Furthermore, it integrates with Google's Gemini 1.5 Flash to provide preliminary, AI-generated treatment recommendations based on the diagnosed disease.

## Features

-   **Image Upload:** Users can upload a maize leaf image (PNG, JPG, JPEG).
-   **Disease Prediction:** Classifies the uploaded image into one of four categories: Blight, Common Rust, Gray Leaf Spot, or Healthy.
-   **Confidence Score:** Displays the prediction probability.
-   **Intuitive UI:** Built with Streamlit for a simple and interactive user experience.
-   **AI-Powered Recommendations:** Provides general treatment recommendations for diagnosed diseases, generated by the Gemini 1.5 Flash large language model.

## How to Run Locally

To explore the project, train the model, or run the Streamlit application on your local machine, follow these steps:

1.  **Clone the Repository:**
    Start by cloning the entire project repository from GitHub to your local machine:
    ```bash
    git clone [https://github.com/Mannienox/Maize_Disease_Prediction_Using_Transfer_Learning_Techniques](https://github.com/Mannienox/Maize_Disease_Prediction_Using_Transfer_Learning_Techniques)
    cd Maize_Disease_Prediction_Using_Transfer_Learning_Techniques
    ```

2.  **Install Git LFS (if not already installed):**
    If the model file (`.pth`) is managed by Git Large File Storage (LFS) due to its size, ensure Git LFS is installed and active:
    ```bash
    git lfs install
    git lfs pull
    ```
    *(If the model is downloaded from Google Drive by the `app.py` script, this step is not strictly necessary for running the Streamlit app, but still recommended for completeness if `Notebook.ipynb` also expects it locally.)*

3.  **Create a Virtual Environment (Recommended):**
    It's best practice to set up a dedicated virtual environment for project dependencies:
    ```bash
    python -m venv venv
    # On Windows
    .\venv\Scripts\activate
    # On macOS/Linux
    source venv/bin/activate
    ```

4.  **Install Dependencies:**
    Install all necessary Python libraries from the `requirements.txt` file:
    ```bash
    pip install -r requirements.txt
    ```

5.  **Set up Gemini API Key (for recommendations):**
    If you wish to use the AI-powered recommendation feature, you need a Gemini API key. Create a folder named `.streamlit` in your project's root directory. Inside it, create a file named `secrets.toml`.
    Add your Gemini API key:
    ```toml
    # .streamlit/secrets.toml
    GEMINI_API_KEY = "YOUR_GEMINI_API_KEY_HERE"
    ```
    (Replace `YOUR_GEMINI_API_KEY_HERE` with your actual key from [Google AI Studio](https://aistudio.google.com/)).

6.  **Explore and Run the Notebook:**
    The core development, training, and evaluation process is documented within the `Notebook.ipynb` file. This notebook utilizes the modular Python scripts (`engine.py`, `setup.py`, `plot_lib.py`, `predict.py`, `train_model.py`) for various functionalities. The trained model weights will be saved in the `Model/` folder.

    To open and run the notebook:
    ```bash
    jupyter notebook Notebook.ipynb
    ```
    Follow the instructions within the notebook cells to execute the code, train the model, and understand its performance.

7.  **Run the Streamlit App (Optional, after model training/download):**
    Once the model is available (either locally after training in the notebook, via Git LFS, or downloaded by the app from Google Drive), you can run the interactive web application:
    ```bash
    streamlit run app.py
    ```
    This will launch the app in your default web browser.

## Live Streamlit App

You can access the deployed version of the Maize Disease Predictor directly on Streamlit Community Cloud:

[**Live Demo Link**](https://maizediseasepredictorv1.streamlit.app/)

## Dataset

The model was trained on the **Corn or Maize Leaf Disease Dataset** available on Kaggle:

[**Kaggle Dataset Link**](https://www.kaggle.com/datasets/smaranjitghose/corn-or-maize-leaf-disease-dataset)

This dataset contains images of maize leaves categorized into:
-   Blight
-   Common Rust
-   Gray Leaf Spot
-   Healthy

## Model Details

-   **Architecture:** Fine-tuned ResNet50 (pre-trained on ImageNet).
-   **Transfer Learning:** The backbone layers of ResNet50 were frozen, and a custom classification head was trained for the specific disease classes.
-   **Training:** The model was trained for [e.g., 10 epochs] using [e.g., Adam optimizer] with a learning rate of [e.g., 0.001].
-   **Framework:** PyTorch.

## Project Structure

The repository is organized as follows:


â”œâ”€â”€ Notebook.ipynb          # Main notebook for training, evaluation, and exploration

â”œâ”€â”€ Models/                     # To store trained model weights

â”‚   â””â”€â”€ resnet50_10_epochs_adam_0_001.pth

â”œâ”€â”€ __init__.py             # Makes 'src' a Python package (can be empty)

â”œâ”€â”€ app.py                  # Your Streamlit web application script

â”œâ”€â”€ engine.py               # Functions for training and testing loops

â”œâ”€â”€ plot_lib.py             # Functions for plotting accuracy and loss curves

â”œâ”€â”€ predict.py              # Function for single image prediction

â”œâ”€â”€ setup.py                # Data preparation functions (e.g., prepare_data)

â”œâ”€â”€ train_model.py          # Script for orchestrating the training process

â”œâ”€â”€ .gitignore                  # Specifies intentionally untracked files to ignore

â”œâ”€â”€ README.md                   # Project overview, setup, how-to-run, links, etc.

â””â”€â”€ requirements.txt            # List of all Python dependencies

## Group Members

This project was developed as a collaborative effort by the following members from Arewa Data Science Academy's Deep Learning Cohort 2.0:

-   Khadijah Sani-Musa
-   Abdulazeez Ahmad
-   Ibrahim Manasseh
-   Ibrahim Hamza Maishanu

## Acknowledgements

We extend our sincere gratitude to the **Arewa Data Science Academy** for providing the invaluable Deep Learning Fellowship Cohort 2.0, equipping us with the knowledge and support necessary to complete this project. Special thanks to the mentors and the vibrant community for their guidance and encouragement.

---
